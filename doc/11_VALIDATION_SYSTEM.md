# Airis 出力検証システム

## バージョン情報

| 項目 | 内容 |
|------|------|
| 作成日 | 2025-10-13 |
| バージョン | 2.2.0 |
| 機能名 | AI Output Validation System |

---

## 1. 概要

Airisの出力検証システムは、AIエージェントが生成した結果を別のAIが自動的にダブルチェックし、品質を保証する機能です。

### 1.1 目的

- **品質保証**: AIの出力が基準を満たしているか確認
- **エラー検出**: 明らかな誤りや矛盾を自動検出
- **ユーザー負担軽減**: 人間が細かくチェックする必要を削減
- **信頼性向上**: AI同士の相互チェックで精度向上

### 1.2 メリット

✅ **自動品質管理**: 人間の介入なしで品質チェック
✅ **即座のフィードバック**: 問題があれば即座に検出
✅ **学習効果**: 検証結果から改善ポイントを特定
✅ **透明性**: 検証プロセスと結果をユーザーに表示

---

## 2. アーキテクチャ

### 2.1 検証フロー

```
┌─────────────────────────────────────────────────────────────┐
│  1. ユーザー指示                                            │
│     "generate requirements"                                 │
└─────────────────┬───────────────────────────────────────────┘
                  │
                  ▼
┌─────────────────────────────────────────────────────────────┐
│  2. タスク実行                                              │
│     - Gemini Agentがドキュメント生成                        │
│     - 出力: 要件定義書                                      │
└─────────────────┬───────────────────────────────────────────┘
                  │
                  ▼
┌─────────────────────────────────────────────────────────────┐
│  3. 検証判定                                                │
│     ┌────────────────────────────────┐                      │
│     │ 検証が有効か？                 │                      │
│     │ - enable_output_validation     │                      │
│     └────────┬───────────────────────┘                      │
│              │ Yes                                           │
│     ┌────────▼───────────────────────┐                      │
│     │ このタスクは検証対象か？       │                      │
│     │ - validation_tasks設定を確認   │                      │
│     └────────┬───────────────────────┘                      │
│              │ Yes                                           │
│     ┌────────▼───────────────────────┐                      │
│     │ 出力が十分な長さか？           │                      │
│     │ - 50文字以上                   │                      │
│     └────────┬───────────────────────┘                      │
│              │ Yes                                           │
└──────────────┼─────────────────────────────────────────────┘
               │
               ▼
┌─────────────────────────────────────────────────────────────┐
│  4. ValidatorAgent実行                                      │
│     - 元の指示と出力を分析                                  │
│     - LLM（Claude）による品質評価                          │
│     - 4つの観点から検証：                                   │
│       1. 正確性: 指示に対応しているか                       │
│       2. 完全性: 必要な情報が含まれているか                 │
│       3. 品質: 内容が適切でわかりやすいか                   │
│       4. エラー: 明らかな誤りがないか                       │
└─────────────────┬───────────────────────────────────────────┘
                  │
                  ▼
┌─────────────────────────────────────────────────────────────┐
│  5. 検証結果の判定                                          │
│     ┌────────────────────────────────┐                      │
│     │ OK: 品質基準を満たしている      │ ✓                   │
│     ├────────────────────────────────┤                      │
│     │ NG: 重大な問題がある            │ ✗                   │
│     ├────────────────────────────────┤                      │
│     │ NEEDS_IMPROVEMENT: 改善の余地   │ ⚠                   │
│     └────────────────────────────────┘                      │
└─────────────────┬───────────────────────────────────────────┘
                  │
                  ▼
┌─────────────────────────────────────────────────────────────┐
│  6. ユーザーへの返却                                        │
│     - 元の出力                                              │
│     - 検証結果メッセージ                                    │
│       「✓ 検証完了: 品質基準を満たしています」              │
└─────────────────────────────────────────────────────────────┘
```

---

## 3. コンポーネント

### 3.1 ValidatorAgent

**ファイル**: `agents/validator_agent.py`

**主要メソッド**:

```python
def execute(instruction: str) -> str:
    """
    検証を実行
    
    入力形式: "validate: <task_type> | <original_prompt> | <output>"
    出力形式: "VALIDATION_OK|<詳細>" or "VALIDATION_NG|<詳細>"
    """
```

**検証プロンプト**:
- タスクタイプ、元の指示、生成された出力を含む
- 4つの観点（正確性、完全性、品質、エラー）から評価
- 構造化された結果を返却

### 3.2 Orchestratorの検証統合

**メソッド**: `_validate_output()`

```python
def _validate_output(task_type, original_prompt, output):
    """
    出力を検証
    
    Returns:
        (is_valid, validated_output, validation_message)
    """
```

**統合ポイント**:
1. コード生成後
2. ドキュメント生成後
3. コード分析後
4. その他、設定で指定されたタスク

---

## 4. 設定

### 4.1 config.yaml設定

```yaml
# Output validation settings
enable_output_validation: true  # 検証機能の有効/無効
validation_tasks:               # 検証対象のタスクタイプ
  - code_generation
  - document_generation
  - code_analysis
```

### 4.2 検証の有効化/無効化

```bash
# 検証を無効にする場合
vim config.yaml
# enable_output_validation: false に変更

# または、特定のタスクのみ検証
validation_tasks:
  - code_generation  # コード生成のみ検証
```

---

## 5. 検証基準

### 5.1 OK（合格）

以下の条件をすべて満たす場合：
- ✅ 元の指示に正確に対応している
- ✅ 必要な情報がすべて含まれている
- ✅ 内容が適切でわかりやすい
- ✅ 明らかな誤りや矛盾がない

**出力例**:
```
--- VALIDATION ---
✓ 検証完了: 品質基準を満たしています
```

### 5.2 NG（不合格）

以下のような重大な問題がある場合：
- ✗ 元の指示と全く異なる内容
- ✗ 致命的なエラーや矛盾
- ✗ 必須情報の大幅な欠落
- ✗ セキュリティ上の重大な問題

**出力例**:
```
--- VALIDATION ---
✗ 検証失敗:
【理由】: 要件定義書に必須セクションが欠落しています
【問題点】: 非機能要件のセクションが含まれていません
```

### 5.3 NEEDS_IMPROVEMENT（改善推奨）

以下のような改善の余地がある場合：
- ⚠ 表現が不明瞭
- ⚠ 詳細が不足
- ⚠ 構造が不適切
- ⚠ より良い代替案がある

**出力例**:
```
--- VALIDATION ---
⚠ 改善推奨:
【理由】: コードは動作しますが、エラーハンドリングが不足しています
【改善提案】: try-except ブロックを追加することを推奨します
```

---

## 6. 使用例

### 6.1 コード生成の検証

```bash
$ echo y | docker-compose run -T --rm airis python3 -m airis.main \
  "code generate: Create a calculator with error handling"

--- RESULT ---
# Simple Calculator Code

[生成されたコード...]

--- VALIDATION ---
✓ 検証完了: 品質基準を満たしています
【理由】: コードは要件を満たし、適切なエラーハンドリングが実装されています
```

### 6.2 ドキュメント生成の検証

```bash
$ echo y | docker-compose run -T --rm airis python3 -m airis.main \
  "generate requirements"

--- RESULT ---
# プロジェクト要件定義書

[生成されたドキュメント...]

--- VALIDATION ---
✓ 検証完了: 品質基準を満たしています
【理由】: すべての必須セクションが含まれ、内容も適切です
```

### 6.3 コード分析の検証

```bash
$ echo y | docker-compose run -T --rm airis python3 -m airis.main \
  "gemini analyze code: print('hello')"

--- RESULT ---
[詳細な分析結果...]

--- VALIDATION ---
✓ 検証完了: 品質基準を満たしています
【理由】: 4つの観点から適切に分析されています
```

---

## 7. パフォーマンスへの影響

### 7.1 実行時間

- **通常実行**: 5-10秒
- **検証あり**: 8-15秒（+3-5秒）

検証により若干の遅延が発生しますが、品質向上のメリットが上回ります。

### 7.2 APIコスト

- **追加コスト**: 検証1回あたり約1,000-2,000トークン
- **月間想定**: 検証100回 = 約$0.05-0.10（Claudeの場合）

コストは最小限ですが、品質が大幅に向上します。

---

## 8. 検証のスキップ

以下の場合は検証がスキップされます：

1. **検証無効化**: `enable_output_validation: false`
2. **非対象タスク**: `validation_tasks` に含まれないタスク
3. **短い出力**: 50文字未満の出力
4. **特殊コマンド**: `ai engine` コマンドなど
5. **シェル操作**: Git、シェルコマンドなど

---

## 9. カスタマイズ

### 9.1 検証基準の調整

ValidatorAgentのプロンプトを編集して、検証基準をカスタマイズできます：

```python
# agents/validator_agent.py

validation_prompt = f"""あなたは品質管理の専門家です。

【カスタム検証基準】
- コードの可読性スコアが80点以上
- ドキュメントの文字数が1000文字以上
- セキュリティリスクがゼロ

...(以下、検証ロジック)
"""
```

### 9.2 検証対象の追加

```yaml
# config.yaml

validation_tasks:
  - code_generation
  - document_generation
  - code_analysis
  - web_search        # ウェブ検索結果も検証
  - shell_operations  # シェル操作も検証
```

---

## 10. トラブルシューティング

### 10.1 検証が実行されない

**原因**:
- `enable_output_validation: false` になっている
- タスクタイプが `validation_tasks` に含まれていない

**解決方法**:
```yaml
# config.yaml を確認
enable_output_validation: true
validation_tasks:
  - code_generation  # 追加
```

### 10.2 検証がエラーになる

**原因**:
- LLM APIキーが設定されていない
- ネットワークエラー

**解決方法**:
```bash
# .envファイルを確認
ANTHROPIC_API_KEY=sk-...

# Dockerコンテナを再起動
docker-compose restart
```

### 10.3 検証が遅い

**原因**:
- 大量の出力を検証している
- LLM APIのレスポンスが遅い

**解決方法**:
```yaml
# 検証を特定のタスクのみに限定
validation_tasks:
  - code_generation  # コード生成のみ
```

---

## 11. 検証結果の解釈

### 11.1 検証OKの場合

```
--- VALIDATION ---
✓ 検証完了: 品質基準を満たしています
```

**意味**: 出力は品質基準を満たしており、そのまま使用可能です。

### 11.2 検証NGの場合

```
--- VALIDATION ---
✗ 検証失敗:
【理由】: コードに構文エラーがあります
【問題点】: 括弧の閉じ忘れが検出されました
```

**意味**: 重大な問題があります。出力は使用前に修正が必要です。

**推奨対応**:
1. 問題点を確認
2. 再度タスクを実行
3. 問題が続く場合は、より詳細な指示を提供

### 11.3 改善推奨の場合

```
--- VALIDATION ---
⚠ 改善推奨:
【理由】: コードは動作しますが、最適化の余地があります
【改善提案】: エラーハンドリングを追加することを推奨します
```

**意味**: 出力は使用可能ですが、改善の余地があります。

**推奨対応**:
1. 改善提案を確認
2. 必要に応じて修正版を再生成
3. または、そのまま使用して後で改善

---

## 12. 将来の拡張

### 12.1 自動修正機能（Phase 3）

検証NGの場合、自動的に修正を試みる機能：

```
検証NG検出
    ↓
問題点を特定
    ↓
修正プロンプトを生成
    ↓
元のエージェントで再実行
    ↓
再検証
    ↓
OK → ユーザーに返却
```

### 12.2 複数AI相互検証（Phase 4）

複数のAIで検証し、多数決で判定：

```
出力
    ↓
Claude検証 → OK
Gemini検証 → OK
Local検証 → NEEDS_IMPROVEMENT
    ↓
多数決: OK（2票）
```

### 12.3 学習機能（Phase 5）

検証結果を蓄積し、品質傾向を分析：

```
検証結果ログ
    ↓
パターン分析
    ↓
よくある問題を特定
    ↓
プロンプト改善に反映
```

---

## 13. 技術仕様

### 13.1 ValidatorAgentの実装

```python
class ValidatorAgent(BaseAgent):
    def execute(self, instruction: str) -> str:
        # 1. 指示をパース
        task_type, original_prompt, output = parse_instruction(instruction)
        
        # 2. 検証プロンプトを作成
        validation_prompt = create_validation_prompt(
            task_type, original_prompt, output
        )
        
        # 3. LLMに検証を依頼
        validation_result = self.llm_client.invoke(validation_prompt)
        
        # 4. 結果をパース
        status, details = parse_validation_result(validation_result)
        
        # 5. フォーマットして返却
        return f"{status}|{details}"
```

### 13.2 Orchestratorの検証統合

```python
def delegate_task(self, user_prompt: str):
    # 1. タスク実行
    result = agent.execute(user_prompt)
    
    # 2. 検証
    if self.enable_validation and task_type in self.validation_tasks:
        is_valid, validated_result, validation_msg = self._validate_output(
            task_type, user_prompt, result
        )
        result = f"{result}\n\n--- VALIDATION ---\n{validation_msg}"
    
    # 3. 返却
    return result
```

---

## 14. セキュリティとプライバシー

### 14.1 データの取り扱い

- **検証データ**: LLM APIに送信される（一時的）
- **保存**: 検証結果はローカルに保存されない
- **プライバシー**: センシティブ情報の検証は避けるべき

### 14.2 推奨事項

- 機密情報を含む出力は検証を無効化
- 必要に応じてタスクごとに検証をON/OFF
- ローカルLLMの使用を検討（将来実装）

---

## 15. ベストプラクティス

### 15.1 検証を有効にすべきタスク

✅ **コード生成**: 構文エラーやバグの検出
✅ **ドキュメント生成**: 完全性と正確性の確認
✅ **コード分析**: 分析の妥当性確認
✅ **重要な意思決定**: アーキテクチャ設計など

### 15.2 検証をスキップしてよいタスク

⏭ **単純な検索**: Web検索結果
⏭ **ファイル操作**: Git操作、シェルコマンド
⏭ **対話的タスク**: Cursor統合など
⏭ **高速応答が必要**: リアルタイム操作

---

## 16. まとめ

Airisの出力検証システムにより：

1. **品質保証**: AI同士のダブルチェックで精度向上
2. **自動化**: 人間の負担を軽減
3. **透明性**: 検証プロセスを可視化
4. **柔軟性**: タスクごとに検証をカスタマイズ可能

この機能により、Airisはより信頼性の高いAIアシスタントになります。

---

## 付録A: 検証ログの例

### A.1 成功例

```
タスク: ドキュメント生成
元の指示: "generate requirements"
検証結果: OK
理由: すべてのセクションが適切に生成され、内容も充実しています
```

### A.2 失敗例

```
タスク: コード生成
元の指示: "Create a database manager"
検証結果: NG
理由: SQLインジェクションの脆弱性が検出されました
問題点: ユーザー入力をサニタイズせずにSQLクエリに挿入しています
```

### A.3 改善推奨例

```
タスク: コード分析
元の指示: "Analyze this code"
検証結果: NEEDS_IMPROVEMENT
理由: 分析は正確ですが、具体的な改善提案が不足しています
改善提案: パフォーマンス最適化の具体例を追加してください
```

